{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## RNN for Time Series Forecasting\n",
    "https://machinelearningmastery.com/tensorflow-tutorial-deep-learning-with-tf-keras\n",
    "\n",
    "Recurrent Neural Networks, or RNNs for short, are designed to operate upon sequences of data.\n",
    "\n",
    "They have proven to be very effective for natural language processing problems where sequences of text are provided as input to the model.\n",
    "\n",
    "RNNs have also seen some modest success in time series forecasting and speech recognition.\n",
    "\n",
    "The most popular type of RNN is the Long Short-Term Memory network or LSTM for short.\n",
    "\n",
    "LSTMs can be used in a model to accept a sequence of input data and make a prediction, such as assign a class label or predict a numerical value like the next value or values in the sequence.\n",
    "\n",
    "You will use the car sales dataset to demonstrate an LSTM RNN for univariate time series forecasting.\n",
    "\n",
    "This problem involves predicting the number of car sales per month.\n",
    "\n",
    "Let’s frame the problem to take a window of the last five months of data to predict the current month’s data.\n",
    "\n",
    "To achieve this, you define a new function named split_sequence() that will split the input sequence into windows of data appropriate for fitting a supervised learning model, like an LSTM.\n",
    "\n",
    "LSTMs expect each sample in the dataset to have two dimensions; the first is the number of time steps (in this case, it is 5), and the second is the number of observations per time step (in this case, it is 1).\n",
    "\n",
    "Because it is a regression-type problem, we will use a linear activation function (no activation function) in the output layer and optimize the mean squared error loss function.\n",
    "\n",
    "We will also evaluate the model using the mean absolute error (MAE) metric."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-25T10:46:35.886637Z",
     "start_time": "2023-07-25T10:46:35.880201Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as tfl\n",
    "from tensorflow.keras import Sequential"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-25T10:46:43.025841Z",
     "start_time": "2023-07-25T10:46:43.020971Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-25T10:46:43.741723Z",
     "start_time": "2023-07-25T10:46:43.735870Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [],
   "source": [
    "tf.get_logger().setLevel('ERROR')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-25T10:46:44.472553Z",
     "start_time": "2023-07-25T10:46:44.466205Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load the Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [],
   "source": [
    "# split a univariate sequence into samples\n",
    "def split_sequence(sequence, n_steps):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequence)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps\n",
    "        # check if we are beyond the sequence\n",
    "        if end_ix > len(sequence)-1:\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "\n",
    "    return np.asarray(X), np.asarray(y)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-25T10:46:45.631848Z",
     "start_time": "2023-07-25T10:46:45.617385Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/monthly-car-sales.csv'\n",
    "df = pd.read_csv(url, header=0, index_col=0, squeeze=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-25T10:46:46.804079Z",
     "start_time": "2023-07-25T10:46:46.579025Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "data": {
      "text/plain": "Month\n1960-01     6550\n1960-02     8728\n1960-03    12026\n1960-04    14395\n1960-05    14587\n1960-06    13791\n1960-07     9498\n1960-08     8251\n1960-09     7049\n1960-10     9545\nName: Sales, dtype: int64"
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-25T10:46:50.536315Z",
     "start_time": "2023-07-25T10:46:50.529234Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [],
   "source": [
    "# Retrieve the values\n",
    "values = df.values.astype('float32')\n",
    "# Specify the window size\n",
    "n_steps = 5\n",
    "# Split into samples\n",
    "X, y = split_sequence(values, n_steps)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-25T10:46:51.444981Z",
     "start_time": "2023-07-25T10:46:51.432513Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [],
   "source": [
    "# Reshape into [samples, timesteps, features]\n",
    "X = X.reshape((X.shape[0], X.shape[1], 1))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-25T10:46:52.296677Z",
     "start_time": "2023-07-25T10:46:52.286809Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[[ 6550.],\n        [ 8728.],\n        [12026.],\n        [14395.],\n        [14587.]],\n\n       [[ 8728.],\n        [12026.],\n        [14395.],\n        [14587.],\n        [13791.]],\n\n       [[12026.],\n        [14395.],\n        [14587.],\n        [13791.],\n        [ 9498.]],\n\n       [[14395.],\n        [14587.],\n        [13791.],\n        [ 9498.],\n        [ 8251.]],\n\n       [[14587.],\n        [13791.],\n        [ 9498.],\n        [ 8251.],\n        [ 7049.]],\n\n       [[13791.],\n        [ 9498.],\n        [ 8251.],\n        [ 7049.],\n        [ 9545.]],\n\n       [[ 9498.],\n        [ 8251.],\n        [ 7049.],\n        [ 9545.],\n        [ 9364.]],\n\n       [[ 8251.],\n        [ 7049.],\n        [ 9545.],\n        [ 9364.],\n        [ 8456.]],\n\n       [[ 7049.],\n        [ 9545.],\n        [ 9364.],\n        [ 8456.],\n        [ 7237.]],\n\n       [[ 9545.],\n        [ 9364.],\n        [ 8456.],\n        [ 7237.],\n        [ 9374.]],\n\n       [[ 9364.],\n        [ 8456.],\n        [ 7237.],\n        [ 9374.],\n        [11837.]],\n\n       [[ 8456.],\n        [ 7237.],\n        [ 9374.],\n        [11837.],\n        [13784.]],\n\n       [[ 7237.],\n        [ 9374.],\n        [11837.],\n        [13784.],\n        [15926.]],\n\n       [[ 9374.],\n        [11837.],\n        [13784.],\n        [15926.],\n        [13821.]],\n\n       [[11837.],\n        [13784.],\n        [15926.],\n        [13821.],\n        [11143.]],\n\n       [[13784.],\n        [15926.],\n        [13821.],\n        [11143.],\n        [ 7975.]],\n\n       [[15926.],\n        [13821.],\n        [11143.],\n        [ 7975.],\n        [ 7610.]],\n\n       [[13821.],\n        [11143.],\n        [ 7975.],\n        [ 7610.],\n        [10015.]],\n\n       [[11143.],\n        [ 7975.],\n        [ 7610.],\n        [10015.],\n        [12759.]],\n\n       [[ 7975.],\n        [ 7610.],\n        [10015.],\n        [12759.],\n        [ 8816.]],\n\n       [[ 7610.],\n        [10015.],\n        [12759.],\n        [ 8816.],\n        [10677.]],\n\n       [[10015.],\n        [12759.],\n        [ 8816.],\n        [10677.],\n        [10947.]],\n\n       [[12759.],\n        [ 8816.],\n        [10677.],\n        [10947.],\n        [15200.]],\n\n       [[ 8816.],\n        [10677.],\n        [10947.],\n        [15200.],\n        [17010.]],\n\n       [[10677.],\n        [10947.],\n        [15200.],\n        [17010.],\n        [20900.]],\n\n       [[10947.],\n        [15200.],\n        [17010.],\n        [20900.],\n        [16205.]],\n\n       [[15200.],\n        [17010.],\n        [20900.],\n        [16205.],\n        [12143.]],\n\n       [[17010.],\n        [20900.],\n        [16205.],\n        [12143.],\n        [ 8997.]],\n\n       [[20900.],\n        [16205.],\n        [12143.],\n        [ 8997.],\n        [ 5568.]],\n\n       [[16205.],\n        [12143.],\n        [ 8997.],\n        [ 5568.],\n        [11474.]],\n\n       [[12143.],\n        [ 8997.],\n        [ 5568.],\n        [11474.],\n        [12256.]],\n\n       [[ 8997.],\n        [ 5568.],\n        [11474.],\n        [12256.],\n        [10583.]],\n\n       [[ 5568.],\n        [11474.],\n        [12256.],\n        [10583.],\n        [10862.]],\n\n       [[11474.],\n        [12256.],\n        [10583.],\n        [10862.],\n        [10965.]],\n\n       [[12256.],\n        [10583.],\n        [10862.],\n        [10965.],\n        [14405.]],\n\n       [[10583.],\n        [10862.],\n        [10965.],\n        [14405.],\n        [20379.]],\n\n       [[10862.],\n        [10965.],\n        [14405.],\n        [20379.],\n        [20128.]],\n\n       [[10965.],\n        [14405.],\n        [20379.],\n        [20128.],\n        [17816.]],\n\n       [[14405.],\n        [20379.],\n        [20128.],\n        [17816.],\n        [12268.]],\n\n       [[20379.],\n        [20128.],\n        [17816.],\n        [12268.],\n        [ 8642.]],\n\n       [[20128.],\n        [17816.],\n        [12268.],\n        [ 8642.],\n        [ 7962.]],\n\n       [[17816.],\n        [12268.],\n        [ 8642.],\n        [ 7962.],\n        [13932.]],\n\n       [[12268.],\n        [ 8642.],\n        [ 7962.],\n        [13932.],\n        [15936.]],\n\n       [[ 8642.],\n        [ 7962.],\n        [13932.],\n        [15936.],\n        [12628.]],\n\n       [[ 7962.],\n        [13932.],\n        [15936.],\n        [12628.],\n        [12267.]],\n\n       [[13932.],\n        [15936.],\n        [12628.],\n        [12267.],\n        [12470.]],\n\n       [[15936.],\n        [12628.],\n        [12267.],\n        [12470.],\n        [18944.]],\n\n       [[12628.],\n        [12267.],\n        [12470.],\n        [18944.],\n        [21259.]],\n\n       [[12267.],\n        [12470.],\n        [18944.],\n        [21259.],\n        [22015.]],\n\n       [[12470.],\n        [18944.],\n        [21259.],\n        [22015.],\n        [18581.]],\n\n       [[18944.],\n        [21259.],\n        [22015.],\n        [18581.],\n        [15175.]],\n\n       [[21259.],\n        [22015.],\n        [18581.],\n        [15175.],\n        [10306.]],\n\n       [[22015.],\n        [18581.],\n        [15175.],\n        [10306.],\n        [10792.]],\n\n       [[18581.],\n        [15175.],\n        [10306.],\n        [10792.],\n        [14752.]],\n\n       [[15175.],\n        [10306.],\n        [10792.],\n        [14752.],\n        [13754.]],\n\n       [[10306.],\n        [10792.],\n        [14752.],\n        [13754.],\n        [11738.]],\n\n       [[10792.],\n        [14752.],\n        [13754.],\n        [11738.],\n        [12181.]],\n\n       [[14752.],\n        [13754.],\n        [11738.],\n        [12181.],\n        [12965.]],\n\n       [[13754.],\n        [11738.],\n        [12181.],\n        [12965.],\n        [19990.]],\n\n       [[11738.],\n        [12181.],\n        [12965.],\n        [19990.],\n        [23125.]],\n\n       [[12181.],\n        [12965.],\n        [19990.],\n        [23125.],\n        [23541.]],\n\n       [[12965.],\n        [19990.],\n        [23125.],\n        [23541.],\n        [21247.]],\n\n       [[19990.],\n        [23125.],\n        [23541.],\n        [21247.],\n        [15189.]],\n\n       [[23125.],\n        [23541.],\n        [21247.],\n        [15189.],\n        [14767.]],\n\n       [[23541.],\n        [21247.],\n        [15189.],\n        [14767.],\n        [10895.]],\n\n       [[21247.],\n        [15189.],\n        [14767.],\n        [10895.],\n        [17130.]],\n\n       [[15189.],\n        [14767.],\n        [10895.],\n        [17130.],\n        [17697.]],\n\n       [[14767.],\n        [10895.],\n        [17130.],\n        [17697.],\n        [16611.]],\n\n       [[10895.],\n        [17130.],\n        [17697.],\n        [16611.],\n        [12674.]],\n\n       [[17130.],\n        [17697.],\n        [16611.],\n        [12674.],\n        [12760.]],\n\n       [[17697.],\n        [16611.],\n        [12674.],\n        [12760.],\n        [20249.]],\n\n       [[16611.],\n        [12674.],\n        [12760.],\n        [20249.],\n        [22135.]],\n\n       [[12674.],\n        [12760.],\n        [20249.],\n        [22135.],\n        [20677.]],\n\n       [[12760.],\n        [20249.],\n        [22135.],\n        [20677.],\n        [19933.]],\n\n       [[20249.],\n        [22135.],\n        [20677.],\n        [19933.],\n        [15388.]],\n\n       [[22135.],\n        [20677.],\n        [19933.],\n        [15388.],\n        [15113.]],\n\n       [[20677.],\n        [19933.],\n        [15388.],\n        [15113.],\n        [13401.]],\n\n       [[19933.],\n        [15388.],\n        [15113.],\n        [13401.],\n        [16135.]],\n\n       [[15388.],\n        [15113.],\n        [13401.],\n        [16135.],\n        [17562.]],\n\n       [[15113.],\n        [13401.],\n        [16135.],\n        [17562.],\n        [14720.]],\n\n       [[13401.],\n        [16135.],\n        [17562.],\n        [14720.],\n        [12225.]],\n\n       [[16135.],\n        [17562.],\n        [14720.],\n        [12225.],\n        [11608.]],\n\n       [[17562.],\n        [14720.],\n        [12225.],\n        [11608.],\n        [20985.]],\n\n       [[14720.],\n        [12225.],\n        [11608.],\n        [20985.],\n        [19692.]],\n\n       [[12225.],\n        [11608.],\n        [20985.],\n        [19692.],\n        [24081.]],\n\n       [[11608.],\n        [20985.],\n        [19692.],\n        [24081.],\n        [22114.]],\n\n       [[20985.],\n        [19692.],\n        [24081.],\n        [22114.],\n        [14220.]],\n\n       [[19692.],\n        [24081.],\n        [22114.],\n        [14220.],\n        [13434.]],\n\n       [[24081.],\n        [22114.],\n        [14220.],\n        [13434.],\n        [13598.]],\n\n       [[22114.],\n        [14220.],\n        [13434.],\n        [13598.],\n        [17187.]],\n\n       [[14220.],\n        [13434.],\n        [13598.],\n        [17187.],\n        [16119.]],\n\n       [[13434.],\n        [13598.],\n        [17187.],\n        [16119.],\n        [13713.]],\n\n       [[13598.],\n        [17187.],\n        [16119.],\n        [13713.],\n        [13210.]],\n\n       [[17187.],\n        [16119.],\n        [13713.],\n        [13210.],\n        [14251.]],\n\n       [[16119.],\n        [13713.],\n        [13210.],\n        [14251.],\n        [20139.]],\n\n       [[13713.],\n        [13210.],\n        [14251.],\n        [20139.],\n        [21725.]],\n\n       [[13210.],\n        [14251.],\n        [20139.],\n        [21725.],\n        [26099.]],\n\n       [[14251.],\n        [20139.],\n        [21725.],\n        [26099.],\n        [21084.]],\n\n       [[20139.],\n        [21725.],\n        [26099.],\n        [21084.],\n        [18024.]],\n\n       [[21725.],\n        [26099.],\n        [21084.],\n        [18024.],\n        [16722.]],\n\n       [[26099.],\n        [21084.],\n        [18024.],\n        [16722.],\n        [14385.]],\n\n       [[21084.],\n        [18024.],\n        [16722.],\n        [14385.],\n        [21342.]],\n\n       [[18024.],\n        [16722.],\n        [14385.],\n        [21342.],\n        [17180.]]], dtype=float32)"
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-25T10:46:53.135315Z",
     "start_time": "2023-07-25T10:46:53.115785Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(91, 5, 1) (12, 5, 1) (91,) (12,)\n"
     ]
    }
   ],
   "source": [
    "# split into train/test\n",
    "n_test = 12\n",
    "X_train, X_test, y_train, y_test = X[:-n_test], X[-n_test:], y[:-n_test], y[-n_test:]\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-25T10:46:53.855822Z",
     "start_time": "2023-07-25T10:46:53.847920Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 1: Define the Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [],
   "source": [
    "# Define model\n",
    "model = Sequential()\n",
    "model.add(tfl.LSTM(100, activation='relu', kernel_initializer='he_normal', input_shape=(n_steps,1)))\n",
    "model.add(tfl.Dense(50, activation='relu', kernel_initializer='he_normal'))\n",
    "model.add(tfl.Dense(50, activation='relu', kernel_initializer='he_normal'))\n",
    "model.add(tfl.Dense(1))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-25T10:46:55.193233Z",
     "start_time": "2023-07-25T10:46:55.024730Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 2: Compile the Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-25T10:46:56.654627Z",
     "start_time": "2023-07-25T10:46:56.641181Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 3: Fit the Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/350\n",
      "3/3 - 3s - loss: 347613824.0000 - mae: 14534.6211 - val_loss: 273626784.0000 - val_mae: 12333.8975 - 3s/epoch - 961ms/step\n",
      "Epoch 2/350\n",
      "3/3 - 0s - loss: 206761104.0000 - mae: 10680.3291 - val_loss: 167955792.0000 - val_mae: 10634.9658 - 38ms/epoch - 13ms/step\n",
      "Epoch 3/350\n",
      "3/3 - 0s - loss: 98178152.0000 - mae: 7993.7803 - val_loss: 117340248.0000 - val_mae: 9360.7275 - 38ms/epoch - 13ms/step\n",
      "Epoch 4/350\n",
      "3/3 - 0s - loss: 61082988.0000 - mae: 6131.4238 - val_loss: 76033960.0000 - val_mae: 7070.2739 - 40ms/epoch - 13ms/step\n",
      "Epoch 5/350\n",
      "3/3 - 0s - loss: 65856316.0000 - mae: 6403.0586 - val_loss: 66113532.0000 - val_mae: 5745.4526 - 38ms/epoch - 13ms/step\n",
      "Epoch 6/350\n",
      "3/3 - 0s - loss: 35067416.0000 - mae: 4516.0068 - val_loss: 27889174.0000 - val_mae: 4339.9458 - 41ms/epoch - 14ms/step\n",
      "Epoch 7/350\n",
      "3/3 - 0s - loss: 39777512.0000 - mae: 4661.7812 - val_loss: 61759172.0000 - val_mae: 5656.0630 - 40ms/epoch - 13ms/step\n",
      "Epoch 8/350\n",
      "3/3 - 0s - loss: 50142128.0000 - mae: 5430.6719 - val_loss: 87371352.0000 - val_mae: 8093.9556 - 38ms/epoch - 13ms/step\n",
      "Epoch 9/350\n",
      "3/3 - 0s - loss: 50503172.0000 - mae: 5581.5562 - val_loss: 89424408.0000 - val_mae: 8005.2500 - 38ms/epoch - 13ms/step\n",
      "Epoch 10/350\n",
      "3/3 - 0s - loss: 47380480.0000 - mae: 5575.5132 - val_loss: 68028824.0000 - val_mae: 7287.5718 - 38ms/epoch - 13ms/step\n",
      "Epoch 11/350\n",
      "3/3 - 0s - loss: 43465184.0000 - mae: 5163.3652 - val_loss: 28371856.0000 - val_mae: 4383.1587 - 36ms/epoch - 12ms/step\n",
      "Epoch 12/350\n",
      "3/3 - 0s - loss: 26110290.0000 - mae: 3981.9458 - val_loss: 43171572.0000 - val_mae: 4864.2588 - 37ms/epoch - 12ms/step\n",
      "Epoch 13/350\n",
      "3/3 - 0s - loss: 24066332.0000 - mae: 3969.6072 - val_loss: 40084352.0000 - val_mae: 4636.6626 - 37ms/epoch - 12ms/step\n",
      "Epoch 14/350\n",
      "3/3 - 0s - loss: 24229868.0000 - mae: 3959.0432 - val_loss: 36883776.0000 - val_mae: 4338.1997 - 36ms/epoch - 12ms/step\n",
      "Epoch 15/350\n",
      "3/3 - 0s - loss: 25761722.0000 - mae: 3983.8318 - val_loss: 33064234.0000 - val_mae: 4273.8628 - 40ms/epoch - 13ms/step\n",
      "Epoch 16/350\n",
      "3/3 - 0s - loss: 21097532.0000 - mae: 3583.8218 - val_loss: 27186864.0000 - val_mae: 4141.3984 - 39ms/epoch - 13ms/step\n",
      "Epoch 17/350\n",
      "3/3 - 0s - loss: 18320738.0000 - mae: 3450.5911 - val_loss: 20379570.0000 - val_mae: 3631.2400 - 42ms/epoch - 14ms/step\n",
      "Epoch 18/350\n",
      "3/3 - 0s - loss: 19651612.0000 - mae: 3440.7769 - val_loss: 33717480.0000 - val_mae: 4566.1978 - 38ms/epoch - 13ms/step\n",
      "Epoch 19/350\n",
      "3/3 - 0s - loss: 18390210.0000 - mae: 3361.0278 - val_loss: 39700880.0000 - val_mae: 5141.3394 - 37ms/epoch - 12ms/step\n",
      "Epoch 20/350\n",
      "3/3 - 0s - loss: 19524934.0000 - mae: 3499.9417 - val_loss: 37102516.0000 - val_mae: 4996.4141 - 37ms/epoch - 12ms/step\n",
      "Epoch 21/350\n",
      "3/3 - 0s - loss: 18551942.0000 - mae: 3454.0344 - val_loss: 24706736.0000 - val_mae: 3913.7131 - 37ms/epoch - 12ms/step\n",
      "Epoch 22/350\n",
      "3/3 - 0s - loss: 17190670.0000 - mae: 3342.5894 - val_loss: 19791158.0000 - val_mae: 3643.1277 - 38ms/epoch - 13ms/step\n",
      "Epoch 23/350\n",
      "3/3 - 0s - loss: 16733664.0000 - mae: 3369.9629 - val_loss: 17824372.0000 - val_mae: 3705.3992 - 36ms/epoch - 12ms/step\n",
      "Epoch 24/350\n",
      "3/3 - 0s - loss: 16857776.0000 - mae: 3392.8713 - val_loss: 16949784.0000 - val_mae: 3764.6025 - 38ms/epoch - 13ms/step\n",
      "Epoch 25/350\n",
      "3/3 - 0s - loss: 15706089.0000 - mae: 3292.0801 - val_loss: 16575151.0000 - val_mae: 3732.4768 - 36ms/epoch - 12ms/step\n",
      "Epoch 26/350\n",
      "3/3 - 0s - loss: 15819140.0000 - mae: 3276.2231 - val_loss: 16636696.0000 - val_mae: 3664.0566 - 37ms/epoch - 12ms/step\n",
      "Epoch 27/350\n",
      "3/3 - 0s - loss: 14303871.0000 - mae: 3135.5691 - val_loss: 19039256.0000 - val_mae: 3667.6863 - 37ms/epoch - 12ms/step\n",
      "Epoch 28/350\n",
      "3/3 - 0s - loss: 14420075.0000 - mae: 3153.0422 - val_loss: 19431454.0000 - val_mae: 3567.8855 - 37ms/epoch - 12ms/step\n",
      "Epoch 29/350\n",
      "3/3 - 0s - loss: 13566110.0000 - mae: 3061.1746 - val_loss: 18470650.0000 - val_mae: 3547.2590 - 38ms/epoch - 13ms/step\n",
      "Epoch 30/350\n",
      "3/3 - 0s - loss: 13178680.0000 - mae: 3003.7236 - val_loss: 18001954.0000 - val_mae: 3534.9954 - 37ms/epoch - 12ms/step\n",
      "Epoch 31/350\n",
      "3/3 - 0s - loss: 12764287.0000 - mae: 2927.9224 - val_loss: 17994566.0000 - val_mae: 3551.2424 - 36ms/epoch - 12ms/step\n",
      "Epoch 32/350\n",
      "3/3 - 0s - loss: 12547563.0000 - mae: 2913.1848 - val_loss: 16849158.0000 - val_mae: 3551.6836 - 38ms/epoch - 13ms/step\n",
      "Epoch 33/350\n",
      "3/3 - 0s - loss: 12257815.0000 - mae: 2835.5542 - val_loss: 16714691.0000 - val_mae: 3567.1331 - 36ms/epoch - 12ms/step\n",
      "Epoch 34/350\n",
      "3/3 - 0s - loss: 12389120.0000 - mae: 2830.3484 - val_loss: 16811352.0000 - val_mae: 3536.3474 - 36ms/epoch - 12ms/step\n",
      "Epoch 35/350\n",
      "3/3 - 0s - loss: 12220780.0000 - mae: 2787.2080 - val_loss: 16917198.0000 - val_mae: 3544.1311 - 37ms/epoch - 12ms/step\n",
      "Epoch 36/350\n",
      "3/3 - 0s - loss: 11610886.0000 - mae: 2689.5703 - val_loss: 18023806.0000 - val_mae: 3536.7019 - 37ms/epoch - 12ms/step\n",
      "Epoch 37/350\n",
      "3/3 - 0s - loss: 11577701.0000 - mae: 2728.7844 - val_loss: 18603058.0000 - val_mae: 3572.9368 - 38ms/epoch - 13ms/step\n",
      "Epoch 38/350\n",
      "3/3 - 0s - loss: 11564476.0000 - mae: 2726.2424 - val_loss: 17352466.0000 - val_mae: 3479.1267 - 37ms/epoch - 12ms/step\n",
      "Epoch 39/350\n",
      "3/3 - 0s - loss: 11127557.0000 - mae: 2592.7310 - val_loss: 17111834.0000 - val_mae: 3544.1438 - 37ms/epoch - 12ms/step\n",
      "Epoch 40/350\n",
      "3/3 - 0s - loss: 11220709.0000 - mae: 2613.5500 - val_loss: 17516024.0000 - val_mae: 3480.3967 - 38ms/epoch - 13ms/step\n",
      "Epoch 41/350\n",
      "3/3 - 0s - loss: 10834152.0000 - mae: 2624.2527 - val_loss: 18194562.0000 - val_mae: 3556.5703 - 37ms/epoch - 12ms/step\n",
      "Epoch 42/350\n",
      "3/3 - 0s - loss: 10823799.0000 - mae: 2607.8142 - val_loss: 17385842.0000 - val_mae: 3478.0750 - 37ms/epoch - 12ms/step\n",
      "Epoch 43/350\n",
      "3/3 - 0s - loss: 10936079.0000 - mae: 2556.2839 - val_loss: 17130498.0000 - val_mae: 3501.5447 - 37ms/epoch - 12ms/step\n",
      "Epoch 44/350\n",
      "3/3 - 0s - loss: 10815180.0000 - mae: 2567.5808 - val_loss: 17981526.0000 - val_mae: 3556.9485 - 36ms/epoch - 12ms/step\n",
      "Epoch 45/350\n",
      "3/3 - 0s - loss: 10473849.0000 - mae: 2573.5996 - val_loss: 17930070.0000 - val_mae: 3580.1936 - 37ms/epoch - 12ms/step\n",
      "Epoch 46/350\n",
      "3/3 - 0s - loss: 10422375.0000 - mae: 2543.3132 - val_loss: 17286684.0000 - val_mae: 3504.7754 - 37ms/epoch - 12ms/step\n",
      "Epoch 47/350\n",
      "3/3 - 0s - loss: 10411344.0000 - mae: 2502.7981 - val_loss: 17490284.0000 - val_mae: 3527.9036 - 37ms/epoch - 12ms/step\n",
      "Epoch 48/350\n",
      "3/3 - 0s - loss: 10082073.0000 - mae: 2508.1436 - val_loss: 20138182.0000 - val_mae: 3830.7839 - 36ms/epoch - 12ms/step\n",
      "Epoch 49/350\n",
      "3/3 - 0s - loss: 11475652.0000 - mae: 2688.1531 - val_loss: 20000630.0000 - val_mae: 3630.6113 - 36ms/epoch - 12ms/step\n",
      "Epoch 50/350\n",
      "3/3 - 0s - loss: 13277901.0000 - mae: 2810.6599 - val_loss: 20058466.0000 - val_mae: 3791.7820 - 36ms/epoch - 12ms/step\n",
      "Epoch 51/350\n",
      "3/3 - 0s - loss: 13659159.0000 - mae: 2969.7224 - val_loss: 27443274.0000 - val_mae: 4799.0776 - 38ms/epoch - 13ms/step\n",
      "Epoch 52/350\n",
      "3/3 - 0s - loss: 15147644.0000 - mae: 3156.3879 - val_loss: 19786298.0000 - val_mae: 3773.4778 - 37ms/epoch - 12ms/step\n",
      "Epoch 53/350\n",
      "3/3 - 0s - loss: 12261971.0000 - mae: 2867.8428 - val_loss: 14529084.0000 - val_mae: 3071.8083 - 37ms/epoch - 12ms/step\n",
      "Epoch 54/350\n",
      "3/3 - 0s - loss: 10644324.0000 - mae: 2682.1816 - val_loss: 18626660.0000 - val_mae: 3387.8721 - 37ms/epoch - 12ms/step\n",
      "Epoch 55/350\n",
      "3/3 - 0s - loss: 11236529.0000 - mae: 2620.4924 - val_loss: 23824080.0000 - val_mae: 4017.1582 - 37ms/epoch - 12ms/step\n",
      "Epoch 56/350\n",
      "3/3 - 0s - loss: 11089793.0000 - mae: 2632.0767 - val_loss: 21047770.0000 - val_mae: 3572.3496 - 36ms/epoch - 12ms/step\n",
      "Epoch 57/350\n",
      "3/3 - 0s - loss: 13648775.0000 - mae: 3030.0459 - val_loss: 23351802.0000 - val_mae: 3818.5671 - 37ms/epoch - 12ms/step\n",
      "Epoch 58/350\n",
      "3/3 - 0s - loss: 12912111.0000 - mae: 2874.4634 - val_loss: 17423112.0000 - val_mae: 3403.3337 - 35ms/epoch - 12ms/step\n",
      "Epoch 59/350\n",
      "3/3 - 0s - loss: 11115397.0000 - mae: 2573.3635 - val_loss: 15782879.0000 - val_mae: 3076.2146 - 38ms/epoch - 13ms/step\n",
      "Epoch 60/350\n",
      "3/3 - 0s - loss: 10411922.0000 - mae: 2631.1052 - val_loss: 14512277.0000 - val_mae: 3004.6194 - 37ms/epoch - 12ms/step\n",
      "Epoch 61/350\n",
      "3/3 - 0s - loss: 10376783.0000 - mae: 2496.6895 - val_loss: 15187317.0000 - val_mae: 3188.3040 - 36ms/epoch - 12ms/step\n",
      "Epoch 62/350\n",
      "3/3 - 0s - loss: 15708512.0000 - mae: 3077.6462 - val_loss: 18761918.0000 - val_mae: 3783.4519 - 36ms/epoch - 12ms/step\n",
      "Epoch 63/350\n",
      "3/3 - 0s - loss: 14672696.0000 - mae: 2984.4685 - val_loss: 14252780.0000 - val_mae: 3129.5984 - 38ms/epoch - 13ms/step\n",
      "Epoch 64/350\n",
      "3/3 - 0s - loss: 13975200.0000 - mae: 2977.5513 - val_loss: 14703772.0000 - val_mae: 2814.7288 - 36ms/epoch - 12ms/step\n",
      "Epoch 65/350\n",
      "3/3 - 0s - loss: 14453195.0000 - mae: 3030.9331 - val_loss: 12722464.0000 - val_mae: 2953.3591 - 37ms/epoch - 12ms/step\n",
      "Epoch 66/350\n",
      "3/3 - 0s - loss: 12674307.0000 - mae: 2716.2815 - val_loss: 13097339.0000 - val_mae: 2920.5762 - 36ms/epoch - 12ms/step\n",
      "Epoch 67/350\n",
      "3/3 - 0s - loss: 10959925.0000 - mae: 2712.1653 - val_loss: 12785057.0000 - val_mae: 2998.9922 - 37ms/epoch - 12ms/step\n",
      "Epoch 68/350\n",
      "3/3 - 0s - loss: 10387092.0000 - mae: 2592.7112 - val_loss: 13792397.0000 - val_mae: 3174.1394 - 38ms/epoch - 13ms/step\n",
      "Epoch 69/350\n",
      "3/3 - 0s - loss: 12524274.0000 - mae: 2739.6238 - val_loss: 10614165.0000 - val_mae: 2784.4431 - 37ms/epoch - 12ms/step\n",
      "Epoch 70/350\n",
      "3/3 - 0s - loss: 9764756.0000 - mae: 2483.9146 - val_loss: 13545304.0000 - val_mae: 2763.9656 - 38ms/epoch - 13ms/step\n",
      "Epoch 71/350\n",
      "3/3 - 0s - loss: 9527975.0000 - mae: 2515.4524 - val_loss: 11723351.0000 - val_mae: 2884.0735 - 37ms/epoch - 12ms/step\n",
      "Epoch 72/350\n",
      "3/3 - 0s - loss: 11257938.0000 - mae: 2598.6790 - val_loss: 9159157.0000 - val_mae: 2558.8635 - 37ms/epoch - 12ms/step\n",
      "Epoch 73/350\n",
      "3/3 - 0s - loss: 9325899.0000 - mae: 2512.6165 - val_loss: 11827005.0000 - val_mae: 2757.7639 - 38ms/epoch - 13ms/step\n",
      "Epoch 74/350\n",
      "3/3 - 0s - loss: 8780270.0000 - mae: 2400.8867 - val_loss: 20501112.0000 - val_mae: 3443.8848 - 37ms/epoch - 12ms/step\n",
      "Epoch 75/350\n",
      "3/3 - 0s - loss: 8167206.5000 - mae: 2265.8079 - val_loss: 14868725.0000 - val_mae: 3097.2717 - 39ms/epoch - 13ms/step\n",
      "Epoch 76/350\n",
      "3/3 - 0s - loss: 8685538.0000 - mae: 2304.2659 - val_loss: 11280821.0000 - val_mae: 2789.0422 - 36ms/epoch - 12ms/step\n",
      "Epoch 77/350\n",
      "3/3 - 0s - loss: 10446745.0000 - mae: 2448.7058 - val_loss: 10263795.0000 - val_mae: 2851.5857 - 38ms/epoch - 13ms/step\n",
      "Epoch 78/350\n",
      "3/3 - 0s - loss: 10855488.0000 - mae: 2497.4646 - val_loss: 15939292.0000 - val_mae: 3364.8650 - 37ms/epoch - 12ms/step\n",
      "Epoch 79/350\n",
      "3/3 - 0s - loss: 11064425.0000 - mae: 2561.0530 - val_loss: 14284131.0000 - val_mae: 3071.7302 - 37ms/epoch - 12ms/step\n",
      "Epoch 80/350\n",
      "3/3 - 0s - loss: 11479913.0000 - mae: 2611.5669 - val_loss: 15833309.0000 - val_mae: 3224.6218 - 37ms/epoch - 12ms/step\n",
      "Epoch 81/350\n",
      "3/3 - 0s - loss: 10697961.0000 - mae: 2489.5513 - val_loss: 15835847.0000 - val_mae: 3222.9988 - 37ms/epoch - 12ms/step\n",
      "Epoch 82/350\n",
      "3/3 - 0s - loss: 10193480.0000 - mae: 2435.6357 - val_loss: 15536469.0000 - val_mae: 3121.1897 - 37ms/epoch - 12ms/step\n",
      "Epoch 83/350\n",
      "3/3 - 0s - loss: 10132898.0000 - mae: 2497.3914 - val_loss: 13743651.0000 - val_mae: 2967.1875 - 37ms/epoch - 12ms/step\n",
      "Epoch 84/350\n",
      "3/3 - 0s - loss: 9745615.0000 - mae: 2450.0063 - val_loss: 15682404.0000 - val_mae: 2953.7209 - 37ms/epoch - 12ms/step\n",
      "Epoch 85/350\n",
      "3/3 - 0s - loss: 10053221.0000 - mae: 2453.5693 - val_loss: 11795549.0000 - val_mae: 2650.7356 - 36ms/epoch - 12ms/step\n",
      "Epoch 86/350\n",
      "3/3 - 0s - loss: 9585618.0000 - mae: 2455.6372 - val_loss: 13948291.0000 - val_mae: 3225.0549 - 38ms/epoch - 13ms/step\n",
      "Epoch 87/350\n",
      "3/3 - 0s - loss: 11337393.0000 - mae: 2688.7466 - val_loss: 12915109.0000 - val_mae: 2984.9929 - 37ms/epoch - 12ms/step\n",
      "Epoch 88/350\n",
      "3/3 - 0s - loss: 12122727.0000 - mae: 2834.3186 - val_loss: 13064052.0000 - val_mae: 2746.7695 - 37ms/epoch - 12ms/step\n",
      "Epoch 89/350\n",
      "3/3 - 0s - loss: 10905204.0000 - mae: 2597.2048 - val_loss: 14344479.0000 - val_mae: 2988.4700 - 37ms/epoch - 12ms/step\n",
      "Epoch 90/350\n",
      "3/3 - 0s - loss: 11806917.0000 - mae: 2708.6924 - val_loss: 15507540.0000 - val_mae: 3119.7493 - 37ms/epoch - 12ms/step\n",
      "Epoch 91/350\n",
      "3/3 - 0s - loss: 9668078.0000 - mae: 2509.6868 - val_loss: 9723104.0000 - val_mae: 2742.2109 - 37ms/epoch - 12ms/step\n",
      "Epoch 92/350\n",
      "3/3 - 0s - loss: 9496186.0000 - mae: 2541.5691 - val_loss: 13184163.0000 - val_mae: 3167.6667 - 38ms/epoch - 13ms/step\n",
      "Epoch 93/350\n",
      "3/3 - 0s - loss: 10139372.0000 - mae: 2570.3396 - val_loss: 9666057.0000 - val_mae: 2636.1685 - 39ms/epoch - 13ms/step\n",
      "Epoch 94/350\n",
      "3/3 - 0s - loss: 10000883.0000 - mae: 2531.4070 - val_loss: 9770875.0000 - val_mae: 2630.8093 - 38ms/epoch - 13ms/step\n",
      "Epoch 95/350\n",
      "3/3 - 0s - loss: 9041710.0000 - mae: 2346.9690 - val_loss: 11554224.0000 - val_mae: 2765.9482 - 39ms/epoch - 13ms/step\n",
      "Epoch 96/350\n",
      "3/3 - 0s - loss: 10096155.0000 - mae: 2541.4136 - val_loss: 10298911.0000 - val_mae: 2689.3738 - 36ms/epoch - 12ms/step\n",
      "Epoch 97/350\n",
      "3/3 - 0s - loss: 8852052.0000 - mae: 2253.1660 - val_loss: 8636693.0000 - val_mae: 2473.5752 - 37ms/epoch - 12ms/step\n",
      "Epoch 98/350\n",
      "3/3 - 0s - loss: 8361475.0000 - mae: 2228.8279 - val_loss: 9710125.0000 - val_mae: 2542.2595 - 37ms/epoch - 12ms/step\n",
      "Epoch 99/350\n",
      "3/3 - 0s - loss: 8250833.5000 - mae: 2295.4614 - val_loss: 8479647.0000 - val_mae: 2407.2976 - 38ms/epoch - 13ms/step\n",
      "Epoch 100/350\n",
      "3/3 - 0s - loss: 8888423.0000 - mae: 2267.3257 - val_loss: 11433581.0000 - val_mae: 2782.3699 - 39ms/epoch - 13ms/step\n",
      "Epoch 101/350\n",
      "3/3 - 0s - loss: 9787758.0000 - mae: 2421.4653 - val_loss: 12419915.0000 - val_mae: 2819.6934 - 37ms/epoch - 12ms/step\n",
      "Epoch 102/350\n",
      "3/3 - 0s - loss: 10301105.0000 - mae: 2538.0049 - val_loss: 16571868.0000 - val_mae: 3077.8928 - 38ms/epoch - 13ms/step\n",
      "Epoch 103/350\n",
      "3/3 - 0s - loss: 9397908.0000 - mae: 2413.3362 - val_loss: 14888881.0000 - val_mae: 3033.8606 - 39ms/epoch - 13ms/step\n",
      "Epoch 104/350\n",
      "3/3 - 0s - loss: 8653744.0000 - mae: 2308.9570 - val_loss: 12739205.0000 - val_mae: 2759.2500 - 44ms/epoch - 15ms/step\n",
      "Epoch 105/350\n",
      "3/3 - 0s - loss: 11581187.0000 - mae: 2667.4043 - val_loss: 13035815.0000 - val_mae: 2788.5762 - 40ms/epoch - 13ms/step\n",
      "Epoch 106/350\n",
      "3/3 - 0s - loss: 11538504.0000 - mae: 2685.8447 - val_loss: 18673422.0000 - val_mae: 3046.8420 - 44ms/epoch - 15ms/step\n",
      "Epoch 107/350\n",
      "3/3 - 0s - loss: 10472537.0000 - mae: 2594.4421 - val_loss: 18004484.0000 - val_mae: 3824.0281 - 54ms/epoch - 18ms/step\n",
      "Epoch 108/350\n",
      "3/3 - 0s - loss: 11537171.0000 - mae: 2735.1599 - val_loss: 21331284.0000 - val_mae: 3398.3323 - 45ms/epoch - 15ms/step\n",
      "Epoch 109/350\n",
      "3/3 - 0s - loss: 11659218.0000 - mae: 2579.3987 - val_loss: 13988604.0000 - val_mae: 2866.7249 - 40ms/epoch - 13ms/step\n",
      "Epoch 110/350\n",
      "3/3 - 0s - loss: 9928835.0000 - mae: 2473.6194 - val_loss: 14133984.0000 - val_mae: 2909.8562 - 39ms/epoch - 13ms/step\n",
      "Epoch 111/350\n",
      "3/3 - 0s - loss: 11874190.0000 - mae: 2727.3267 - val_loss: 16157169.0000 - val_mae: 3064.3547 - 38ms/epoch - 13ms/step\n",
      "Epoch 112/350\n",
      "3/3 - 0s - loss: 11121987.0000 - mae: 2586.6890 - val_loss: 14015135.0000 - val_mae: 3100.8792 - 41ms/epoch - 14ms/step\n",
      "Epoch 113/350\n",
      "3/3 - 0s - loss: 9735857.0000 - mae: 2363.0542 - val_loss: 14304065.0000 - val_mae: 3040.6907 - 39ms/epoch - 13ms/step\n",
      "Epoch 114/350\n",
      "3/3 - 0s - loss: 10468396.0000 - mae: 2511.4199 - val_loss: 13335305.0000 - val_mae: 3000.6016 - 39ms/epoch - 13ms/step\n",
      "Epoch 115/350\n",
      "3/3 - 0s - loss: 9215129.0000 - mae: 2339.1328 - val_loss: 13728091.0000 - val_mae: 3097.3289 - 39ms/epoch - 13ms/step\n",
      "Epoch 116/350\n",
      "3/3 - 0s - loss: 9417392.0000 - mae: 2354.8071 - val_loss: 16479353.0000 - val_mae: 3295.4617 - 39ms/epoch - 13ms/step\n",
      "Epoch 117/350\n",
      "3/3 - 0s - loss: 9513540.0000 - mae: 2319.0640 - val_loss: 17551422.0000 - val_mae: 3203.0898 - 37ms/epoch - 12ms/step\n",
      "Epoch 118/350\n",
      "3/3 - 0s - loss: 9103352.0000 - mae: 2307.4827 - val_loss: 17242872.0000 - val_mae: 3303.7166 - 42ms/epoch - 14ms/step\n",
      "Epoch 119/350\n",
      "3/3 - 0s - loss: 8930092.0000 - mae: 2317.5188 - val_loss: 14287093.0000 - val_mae: 2974.6101 - 38ms/epoch - 13ms/step\n",
      "Epoch 120/350\n",
      "3/3 - 0s - loss: 8654605.0000 - mae: 2279.0276 - val_loss: 13962509.0000 - val_mae: 2852.1912 - 38ms/epoch - 13ms/step\n",
      "Epoch 121/350\n",
      "3/3 - 0s - loss: 9510522.0000 - mae: 2322.8008 - val_loss: 12336369.0000 - val_mae: 2685.9641 - 37ms/epoch - 12ms/step\n",
      "Epoch 122/350\n",
      "3/3 - 0s - loss: 9545810.0000 - mae: 2489.1089 - val_loss: 12254720.0000 - val_mae: 2840.6848 - 38ms/epoch - 13ms/step\n",
      "Epoch 123/350\n",
      "3/3 - 0s - loss: 9515122.0000 - mae: 2361.6799 - val_loss: 17781338.0000 - val_mae: 3196.8027 - 38ms/epoch - 13ms/step\n",
      "Epoch 124/350\n",
      "3/3 - 0s - loss: 8669679.0000 - mae: 2264.5427 - val_loss: 16908868.0000 - val_mae: 3495.9023 - 38ms/epoch - 13ms/step\n",
      "Epoch 125/350\n",
      "3/3 - 0s - loss: 9455786.0000 - mae: 2487.3286 - val_loss: 16709359.0000 - val_mae: 3198.4756 - 37ms/epoch - 12ms/step\n",
      "Epoch 126/350\n",
      "3/3 - 0s - loss: 9360789.0000 - mae: 2336.4207 - val_loss: 12280440.0000 - val_mae: 2740.9460 - 39ms/epoch - 13ms/step\n",
      "Epoch 127/350\n",
      "3/3 - 0s - loss: 9484956.0000 - mae: 2443.8093 - val_loss: 12234091.0000 - val_mae: 2785.0398 - 39ms/epoch - 13ms/step\n",
      "Epoch 128/350\n",
      "3/3 - 0s - loss: 8622896.0000 - mae: 2281.4558 - val_loss: 14771188.0000 - val_mae: 3032.5598 - 39ms/epoch - 13ms/step\n",
      "Epoch 129/350\n",
      "3/3 - 0s - loss: 7669722.0000 - mae: 2082.9167 - val_loss: 14599181.0000 - val_mae: 3212.3318 - 41ms/epoch - 14ms/step\n",
      "Epoch 130/350\n",
      "3/3 - 0s - loss: 9065382.0000 - mae: 2372.5818 - val_loss: 17846522.0000 - val_mae: 3269.9944 - 39ms/epoch - 13ms/step\n",
      "Epoch 131/350\n",
      "3/3 - 0s - loss: 8610366.0000 - mae: 2179.7866 - val_loss: 15342176.0000 - val_mae: 3073.5654 - 38ms/epoch - 13ms/step\n",
      "Epoch 132/350\n",
      "3/3 - 0s - loss: 9152215.0000 - mae: 2452.4927 - val_loss: 15105145.0000 - val_mae: 3076.0896 - 39ms/epoch - 13ms/step\n",
      "Epoch 133/350\n",
      "3/3 - 0s - loss: 8867522.0000 - mae: 2230.3657 - val_loss: 14675328.0000 - val_mae: 2992.3601 - 38ms/epoch - 13ms/step\n",
      "Epoch 134/350\n",
      "3/3 - 0s - loss: 8757732.0000 - mae: 2368.1362 - val_loss: 16823478.0000 - val_mae: 2972.4949 - 39ms/epoch - 13ms/step\n",
      "Epoch 135/350\n",
      "3/3 - 0s - loss: 8255842.0000 - mae: 2245.5881 - val_loss: 18604162.0000 - val_mae: 3047.7249 - 38ms/epoch - 13ms/step\n",
      "Epoch 136/350\n",
      "3/3 - 0s - loss: 8193489.0000 - mae: 2231.8445 - val_loss: 16817408.0000 - val_mae: 3074.4226 - 37ms/epoch - 12ms/step\n",
      "Epoch 137/350\n",
      "3/3 - 0s - loss: 7908619.5000 - mae: 2231.9331 - val_loss: 14587043.0000 - val_mae: 2782.2490 - 42ms/epoch - 14ms/step\n",
      "Epoch 138/350\n",
      "3/3 - 0s - loss: 8362357.5000 - mae: 2246.8308 - val_loss: 14778720.0000 - val_mae: 3020.6953 - 41ms/epoch - 14ms/step\n",
      "Epoch 139/350\n",
      "3/3 - 0s - loss: 8882101.0000 - mae: 2411.2524 - val_loss: 14392571.0000 - val_mae: 2824.1716 - 39ms/epoch - 13ms/step\n",
      "Epoch 140/350\n",
      "3/3 - 0s - loss: 9517624.0000 - mae: 2337.6497 - val_loss: 15418835.0000 - val_mae: 2860.0605 - 38ms/epoch - 13ms/step\n",
      "Epoch 141/350\n",
      "3/3 - 0s - loss: 8748040.0000 - mae: 2363.8887 - val_loss: 15193153.0000 - val_mae: 2969.3359 - 37ms/epoch - 12ms/step\n",
      "Epoch 142/350\n",
      "3/3 - 0s - loss: 9319162.0000 - mae: 2289.0227 - val_loss: 15660459.0000 - val_mae: 3050.3684 - 36ms/epoch - 12ms/step\n",
      "Epoch 143/350\n",
      "3/3 - 0s - loss: 7495072.5000 - mae: 2156.1772 - val_loss: 17371282.0000 - val_mae: 3463.2507 - 39ms/epoch - 13ms/step\n",
      "Epoch 144/350\n",
      "3/3 - 0s - loss: 8791861.0000 - mae: 2294.6912 - val_loss: 15965823.0000 - val_mae: 3212.9580 - 37ms/epoch - 12ms/step\n",
      "Epoch 145/350\n",
      "3/3 - 0s - loss: 8513978.0000 - mae: 2120.7783 - val_loss: 14970344.0000 - val_mae: 2940.8398 - 39ms/epoch - 13ms/step\n",
      "Epoch 146/350\n",
      "3/3 - 0s - loss: 7849879.0000 - mae: 2207.1558 - val_loss: 14848213.0000 - val_mae: 2905.1941 - 39ms/epoch - 13ms/step\n",
      "Epoch 147/350\n",
      "3/3 - 0s - loss: 7486680.5000 - mae: 2038.4451 - val_loss: 13113873.0000 - val_mae: 2785.3301 - 38ms/epoch - 13ms/step\n",
      "Epoch 148/350\n",
      "3/3 - 0s - loss: 7319441.5000 - mae: 2097.8228 - val_loss: 12252539.0000 - val_mae: 2688.3284 - 38ms/epoch - 13ms/step\n",
      "Epoch 149/350\n",
      "3/3 - 0s - loss: 7129603.5000 - mae: 2012.9921 - val_loss: 11928969.0000 - val_mae: 2656.4314 - 38ms/epoch - 13ms/step\n",
      "Epoch 150/350\n",
      "3/3 - 0s - loss: 7041613.5000 - mae: 1989.7852 - val_loss: 11905947.0000 - val_mae: 2680.4172 - 43ms/epoch - 14ms/step\n",
      "Epoch 151/350\n",
      "3/3 - 0s - loss: 7381622.0000 - mae: 2037.3805 - val_loss: 12833577.0000 - val_mae: 2757.5471 - 38ms/epoch - 13ms/step\n",
      "Epoch 152/350\n",
      "3/3 - 0s - loss: 7164502.0000 - mae: 2044.9180 - val_loss: 13019363.0000 - val_mae: 2796.9890 - 38ms/epoch - 13ms/step\n",
      "Epoch 153/350\n",
      "3/3 - 0s - loss: 7128197.0000 - mae: 1989.1272 - val_loss: 12568619.0000 - val_mae: 2812.8000 - 50ms/epoch - 17ms/step\n",
      "Epoch 154/350\n",
      "3/3 - 0s - loss: 7637643.5000 - mae: 2096.3289 - val_loss: 12549808.0000 - val_mae: 2830.9802 - 38ms/epoch - 13ms/step\n",
      "Epoch 155/350\n",
      "3/3 - 0s - loss: 8145586.5000 - mae: 2137.9575 - val_loss: 12572760.0000 - val_mae: 2789.7610 - 38ms/epoch - 13ms/step\n",
      "Epoch 156/350\n",
      "3/3 - 0s - loss: 7965798.5000 - mae: 2209.5557 - val_loss: 12811240.0000 - val_mae: 2836.9961 - 39ms/epoch - 13ms/step\n",
      "Epoch 157/350\n",
      "3/3 - 0s - loss: 7266885.0000 - mae: 1991.8290 - val_loss: 13203659.0000 - val_mae: 2846.0911 - 41ms/epoch - 14ms/step\n",
      "Epoch 158/350\n",
      "3/3 - 0s - loss: 7278559.0000 - mae: 2016.5305 - val_loss: 12484605.0000 - val_mae: 2883.3486 - 43ms/epoch - 14ms/step\n",
      "Epoch 159/350\n",
      "3/3 - 0s - loss: 7120190.0000 - mae: 2082.0750 - val_loss: 13511911.0000 - val_mae: 2893.1965 - 40ms/epoch - 13ms/step\n",
      "Epoch 160/350\n",
      "3/3 - 0s - loss: 7361436.0000 - mae: 2014.4760 - val_loss: 13151845.0000 - val_mae: 2912.0847 - 38ms/epoch - 13ms/step\n",
      "Epoch 161/350\n",
      "3/3 - 0s - loss: 8384581.0000 - mae: 2284.7188 - val_loss: 12414603.0000 - val_mae: 2770.0813 - 38ms/epoch - 13ms/step\n",
      "Epoch 162/350\n",
      "3/3 - 0s - loss: 7695055.0000 - mae: 2071.1536 - val_loss: 12309105.0000 - val_mae: 2757.5579 - 39ms/epoch - 13ms/step\n",
      "Epoch 163/350\n",
      "3/3 - 0s - loss: 6984107.5000 - mae: 2047.3754 - val_loss: 12104309.0000 - val_mae: 2753.9939 - 38ms/epoch - 13ms/step\n",
      "Epoch 164/350\n",
      "3/3 - 0s - loss: 7105266.0000 - mae: 2087.3435 - val_loss: 12770429.0000 - val_mae: 2875.2214 - 37ms/epoch - 12ms/step\n",
      "Epoch 165/350\n",
      "3/3 - 0s - loss: 6719008.5000 - mae: 1947.6461 - val_loss: 13906197.0000 - val_mae: 2897.5559 - 38ms/epoch - 13ms/step\n",
      "Epoch 166/350\n",
      "3/3 - 0s - loss: 7499193.5000 - mae: 2159.8843 - val_loss: 13004856.0000 - val_mae: 2838.3679 - 39ms/epoch - 13ms/step\n",
      "Epoch 167/350\n",
      "3/3 - 0s - loss: 7480052.0000 - mae: 2043.1741 - val_loss: 12661523.0000 - val_mae: 2718.8359 - 38ms/epoch - 13ms/step\n",
      "Epoch 168/350\n",
      "3/3 - 0s - loss: 7778468.5000 - mae: 2166.4490 - val_loss: 13717620.0000 - val_mae: 2808.8406 - 39ms/epoch - 13ms/step\n",
      "Epoch 169/350\n",
      "3/3 - 0s - loss: 7589230.5000 - mae: 2016.9396 - val_loss: 13274563.0000 - val_mae: 2786.2764 - 37ms/epoch - 12ms/step\n",
      "Epoch 170/350\n",
      "3/3 - 0s - loss: 7307217.0000 - mae: 2105.8540 - val_loss: 12138205.0000 - val_mae: 2697.7395 - 38ms/epoch - 13ms/step\n",
      "Epoch 171/350\n",
      "3/3 - 0s - loss: 7966735.5000 - mae: 2111.2097 - val_loss: 11972117.0000 - val_mae: 2650.0901 - 39ms/epoch - 13ms/step\n",
      "Epoch 172/350\n",
      "3/3 - 0s - loss: 7022462.5000 - mae: 2053.3799 - val_loss: 14265821.0000 - val_mae: 2923.1267 - 39ms/epoch - 13ms/step\n",
      "Epoch 173/350\n",
      "3/3 - 0s - loss: 7200857.5000 - mae: 2073.8799 - val_loss: 14393968.0000 - val_mae: 2807.3411 - 38ms/epoch - 13ms/step\n",
      "Epoch 174/350\n",
      "3/3 - 0s - loss: 7623719.5000 - mae: 2151.4128 - val_loss: 14385447.0000 - val_mae: 2899.7363 - 40ms/epoch - 13ms/step\n",
      "Epoch 175/350\n",
      "3/3 - 0s - loss: 7219562.0000 - mae: 2023.5989 - val_loss: 13777824.0000 - val_mae: 2711.8306 - 48ms/epoch - 16ms/step\n",
      "Epoch 176/350\n",
      "3/3 - 0s - loss: 7012558.0000 - mae: 2024.5560 - val_loss: 14123049.0000 - val_mae: 2896.0801 - 37ms/epoch - 12ms/step\n",
      "Epoch 177/350\n",
      "3/3 - 0s - loss: 6971773.0000 - mae: 2017.6534 - val_loss: 12901845.0000 - val_mae: 2679.3079 - 39ms/epoch - 13ms/step\n",
      "Epoch 178/350\n",
      "3/3 - 0s - loss: 7052483.0000 - mae: 1963.4102 - val_loss: 13007585.0000 - val_mae: 2737.9619 - 38ms/epoch - 13ms/step\n",
      "Epoch 179/350\n",
      "3/3 - 0s - loss: 6998383.0000 - mae: 2028.8521 - val_loss: 13113633.0000 - val_mae: 2743.1162 - 39ms/epoch - 13ms/step\n",
      "Epoch 180/350\n",
      "3/3 - 0s - loss: 7172812.0000 - mae: 1981.1483 - val_loss: 13460089.0000 - val_mae: 2716.5823 - 40ms/epoch - 13ms/step\n",
      "Epoch 181/350\n",
      "3/3 - 0s - loss: 6960578.0000 - mae: 2009.2517 - val_loss: 14148351.0000 - val_mae: 2902.4265 - 37ms/epoch - 12ms/step\n",
      "Epoch 182/350\n",
      "3/3 - 0s - loss: 7042748.5000 - mae: 1960.0297 - val_loss: 12980009.0000 - val_mae: 2665.6824 - 39ms/epoch - 13ms/step\n",
      "Epoch 183/350\n",
      "3/3 - 0s - loss: 7408690.5000 - mae: 2074.8218 - val_loss: 12873677.0000 - val_mae: 2720.3259 - 38ms/epoch - 13ms/step\n",
      "Epoch 184/350\n",
      "3/3 - 0s - loss: 6902251.5000 - mae: 1948.5144 - val_loss: 12848331.0000 - val_mae: 2681.4529 - 37ms/epoch - 12ms/step\n",
      "Epoch 185/350\n",
      "3/3 - 0s - loss: 6822858.5000 - mae: 2001.1508 - val_loss: 13985885.0000 - val_mae: 2866.4060 - 38ms/epoch - 13ms/step\n",
      "Epoch 186/350\n",
      "3/3 - 0s - loss: 6732420.0000 - mae: 1930.2069 - val_loss: 14373564.0000 - val_mae: 2771.3997 - 37ms/epoch - 12ms/step\n",
      "Epoch 187/350\n",
      "3/3 - 0s - loss: 6665266.0000 - mae: 1902.6554 - val_loss: 14749883.0000 - val_mae: 2959.3018 - 37ms/epoch - 12ms/step\n",
      "Epoch 188/350\n",
      "3/3 - 0s - loss: 7318221.5000 - mae: 2086.0559 - val_loss: 13734820.0000 - val_mae: 2722.7014 - 39ms/epoch - 13ms/step\n",
      "Epoch 189/350\n",
      "3/3 - 0s - loss: 7221394.5000 - mae: 1935.6469 - val_loss: 12946475.0000 - val_mae: 2783.2668 - 46ms/epoch - 15ms/step\n",
      "Epoch 190/350\n",
      "3/3 - 0s - loss: 6805905.0000 - mae: 1992.6921 - val_loss: 12796044.0000 - val_mae: 2729.7380 - 38ms/epoch - 13ms/step\n",
      "Epoch 191/350\n",
      "3/3 - 0s - loss: 7165036.5000 - mae: 1993.3016 - val_loss: 13941469.0000 - val_mae: 2853.5618 - 38ms/epoch - 13ms/step\n",
      "Epoch 192/350\n",
      "3/3 - 0s - loss: 6819828.5000 - mae: 1997.4886 - val_loss: 14506299.0000 - val_mae: 2907.6074 - 39ms/epoch - 13ms/step\n",
      "Epoch 193/350\n",
      "3/3 - 0s - loss: 6489065.0000 - mae: 1895.3859 - val_loss: 14065616.0000 - val_mae: 2729.4563 - 38ms/epoch - 13ms/step\n",
      "Epoch 194/350\n",
      "3/3 - 0s - loss: 6886689.0000 - mae: 1920.8774 - val_loss: 13692101.0000 - val_mae: 2834.5198 - 38ms/epoch - 13ms/step\n",
      "Epoch 195/350\n",
      "3/3 - 0s - loss: 6633932.0000 - mae: 1944.9290 - val_loss: 13385801.0000 - val_mae: 2783.1113 - 40ms/epoch - 13ms/step\n",
      "Epoch 196/350\n",
      "3/3 - 0s - loss: 6538285.0000 - mae: 1888.5663 - val_loss: 13124081.0000 - val_mae: 2687.7273 - 49ms/epoch - 16ms/step\n",
      "Epoch 197/350\n",
      "3/3 - 0s - loss: 6608105.0000 - mae: 1888.3265 - val_loss: 13466640.0000 - val_mae: 2763.1250 - 42ms/epoch - 14ms/step\n",
      "Epoch 198/350\n",
      "3/3 - 0s - loss: 6559026.0000 - mae: 1886.8358 - val_loss: 13621723.0000 - val_mae: 2768.7693 - 38ms/epoch - 13ms/step\n",
      "Epoch 199/350\n",
      "3/3 - 0s - loss: 6712564.5000 - mae: 1880.6477 - val_loss: 14234479.0000 - val_mae: 2857.6770 - 38ms/epoch - 13ms/step\n",
      "Epoch 200/350\n",
      "3/3 - 0s - loss: 6697507.0000 - mae: 1982.6077 - val_loss: 13610237.0000 - val_mae: 2800.5596 - 38ms/epoch - 13ms/step\n",
      "Epoch 201/350\n",
      "3/3 - 0s - loss: 6674513.5000 - mae: 1882.0601 - val_loss: 13288136.0000 - val_mae: 2711.2988 - 40ms/epoch - 13ms/step\n",
      "Epoch 202/350\n",
      "3/3 - 0s - loss: 6938245.0000 - mae: 1968.6682 - val_loss: 12567805.0000 - val_mae: 2659.3994 - 39ms/epoch - 13ms/step\n",
      "Epoch 203/350\n",
      "3/3 - 0s - loss: 6594769.0000 - mae: 1869.0419 - val_loss: 13453459.0000 - val_mae: 2702.0120 - 39ms/epoch - 13ms/step\n",
      "Epoch 204/350\n",
      "3/3 - 0s - loss: 6531111.5000 - mae: 1908.8188 - val_loss: 14105485.0000 - val_mae: 2874.9768 - 39ms/epoch - 13ms/step\n",
      "Epoch 205/350\n",
      "3/3 - 0s - loss: 6471544.5000 - mae: 1889.7885 - val_loss: 13431997.0000 - val_mae: 2648.7041 - 48ms/epoch - 16ms/step\n",
      "Epoch 206/350\n",
      "3/3 - 0s - loss: 6543963.5000 - mae: 1852.7976 - val_loss: 13616324.0000 - val_mae: 2815.7649 - 42ms/epoch - 14ms/step\n",
      "Epoch 207/350\n",
      "3/3 - 0s - loss: 7323397.0000 - mae: 2146.9319 - val_loss: 13937144.0000 - val_mae: 2670.0642 - 38ms/epoch - 13ms/step\n",
      "Epoch 208/350\n",
      "3/3 - 0s - loss: 7655697.0000 - mae: 2011.1832 - val_loss: 13325615.0000 - val_mae: 2780.0906 - 37ms/epoch - 12ms/step\n",
      "Epoch 209/350\n",
      "3/3 - 0s - loss: 7095927.5000 - mae: 2091.8076 - val_loss: 13641413.0000 - val_mae: 2829.6270 - 37ms/epoch - 12ms/step\n",
      "Epoch 210/350\n",
      "3/3 - 0s - loss: 7211662.0000 - mae: 2002.6935 - val_loss: 14099189.0000 - val_mae: 2693.2112 - 37ms/epoch - 12ms/step\n",
      "Epoch 211/350\n",
      "3/3 - 0s - loss: 6287835.5000 - mae: 1878.9746 - val_loss: 16317188.0000 - val_mae: 3169.4326 - 37ms/epoch - 12ms/step\n",
      "Epoch 212/350\n",
      "3/3 - 0s - loss: 7369323.5000 - mae: 2133.6240 - val_loss: 13924248.0000 - val_mae: 2833.7363 - 149ms/epoch - 50ms/step\n",
      "Epoch 213/350\n",
      "3/3 - 0s - loss: 7480445.0000 - mae: 2084.2041 - val_loss: 13102475.0000 - val_mae: 2810.7336 - 47ms/epoch - 16ms/step\n",
      "Epoch 214/350\n",
      "3/3 - 0s - loss: 6305836.5000 - mae: 1874.9861 - val_loss: 13465248.0000 - val_mae: 2694.3752 - 40ms/epoch - 13ms/step\n",
      "Epoch 215/350\n",
      "3/3 - 0s - loss: 6764151.5000 - mae: 1885.3628 - val_loss: 13717579.0000 - val_mae: 2810.3015 - 36ms/epoch - 12ms/step\n",
      "Epoch 216/350\n",
      "3/3 - 0s - loss: 7051271.5000 - mae: 2043.6470 - val_loss: 13615616.0000 - val_mae: 2680.5725 - 37ms/epoch - 12ms/step\n",
      "Epoch 217/350\n",
      "3/3 - 0s - loss: 6743156.5000 - mae: 1868.4686 - val_loss: 13955545.0000 - val_mae: 2759.9895 - 37ms/epoch - 12ms/step\n",
      "Epoch 218/350\n",
      "3/3 - 0s - loss: 7584432.0000 - mae: 2149.0483 - val_loss: 13077463.0000 - val_mae: 2708.0190 - 38ms/epoch - 13ms/step\n",
      "Epoch 219/350\n",
      "3/3 - 0s - loss: 8134946.0000 - mae: 2133.5037 - val_loss: 12875495.0000 - val_mae: 2714.2390 - 38ms/epoch - 13ms/step\n",
      "Epoch 220/350\n",
      "3/3 - 0s - loss: 6847129.5000 - mae: 1976.5728 - val_loss: 14155747.0000 - val_mae: 2955.0273 - 36ms/epoch - 12ms/step\n",
      "Epoch 221/350\n",
      "3/3 - 0s - loss: 7069895.5000 - mae: 1964.4807 - val_loss: 12949136.0000 - val_mae: 2641.4700 - 40ms/epoch - 13ms/step\n",
      "Epoch 222/350\n",
      "3/3 - 0s - loss: 6339621.5000 - mae: 1840.7268 - val_loss: 14158487.0000 - val_mae: 3022.2175 - 38ms/epoch - 13ms/step\n",
      "Epoch 223/350\n",
      "3/3 - 0s - loss: 6887259.5000 - mae: 1980.5210 - val_loss: 12200709.0000 - val_mae: 2599.2974 - 40ms/epoch - 13ms/step\n",
      "Epoch 224/350\n",
      "3/3 - 0s - loss: 6779935.5000 - mae: 1898.4252 - val_loss: 12809968.0000 - val_mae: 2688.6926 - 40ms/epoch - 13ms/step\n",
      "Epoch 225/350\n",
      "3/3 - 0s - loss: 6435347.5000 - mae: 1852.1781 - val_loss: 13931359.0000 - val_mae: 2797.9707 - 39ms/epoch - 13ms/step\n",
      "Epoch 226/350\n",
      "3/3 - 0s - loss: 7190297.5000 - mae: 1934.6482 - val_loss: 15057733.0000 - val_mae: 2985.6501 - 38ms/epoch - 13ms/step\n",
      "Epoch 227/350\n",
      "3/3 - 0s - loss: 6847192.5000 - mae: 2043.5110 - val_loss: 13450723.0000 - val_mae: 2779.2361 - 39ms/epoch - 13ms/step\n",
      "Epoch 228/350\n",
      "3/3 - 0s - loss: 6435547.5000 - mae: 1860.1820 - val_loss: 12338157.0000 - val_mae: 2631.5750 - 38ms/epoch - 13ms/step\n",
      "Epoch 229/350\n",
      "3/3 - 0s - loss: 6670466.0000 - mae: 1870.6174 - val_loss: 13434812.0000 - val_mae: 2904.1755 - 39ms/epoch - 13ms/step\n",
      "Epoch 230/350\n",
      "3/3 - 0s - loss: 6427964.0000 - mae: 1935.8989 - val_loss: 14357869.0000 - val_mae: 2877.6204 - 38ms/epoch - 13ms/step\n",
      "Epoch 231/350\n",
      "3/3 - 0s - loss: 7277305.0000 - mae: 1977.0671 - val_loss: 16395567.0000 - val_mae: 3181.5186 - 39ms/epoch - 13ms/step\n",
      "Epoch 232/350\n",
      "3/3 - 0s - loss: 6832989.0000 - mae: 2055.8198 - val_loss: 14172663.0000 - val_mae: 2743.0361 - 39ms/epoch - 13ms/step\n",
      "Epoch 233/350\n",
      "3/3 - 0s - loss: 6904628.0000 - mae: 1877.3025 - val_loss: 12614761.0000 - val_mae: 2767.0713 - 40ms/epoch - 13ms/step\n",
      "Epoch 234/350\n",
      "3/3 - 0s - loss: 7227947.0000 - mae: 2105.8259 - val_loss: 12224583.0000 - val_mae: 2597.1133 - 38ms/epoch - 13ms/step\n",
      "Epoch 235/350\n",
      "3/3 - 0s - loss: 7702275.5000 - mae: 2070.0027 - val_loss: 13226555.0000 - val_mae: 2780.4661 - 38ms/epoch - 13ms/step\n",
      "Epoch 236/350\n",
      "3/3 - 0s - loss: 7747850.5000 - mae: 2140.8950 - val_loss: 14317680.0000 - val_mae: 2813.5247 - 37ms/epoch - 12ms/step\n",
      "Epoch 237/350\n",
      "3/3 - 0s - loss: 7584558.5000 - mae: 1976.7974 - val_loss: 14331443.0000 - val_mae: 2816.0525 - 37ms/epoch - 12ms/step\n",
      "Epoch 238/350\n",
      "3/3 - 0s - loss: 6671136.5000 - mae: 1948.9095 - val_loss: 13485879.0000 - val_mae: 2821.0085 - 37ms/epoch - 12ms/step\n",
      "Epoch 239/350\n",
      "3/3 - 0s - loss: 5936194.0000 - mae: 1788.6689 - val_loss: 13337139.0000 - val_mae: 2750.8279 - 37ms/epoch - 12ms/step\n",
      "Epoch 240/350\n",
      "3/3 - 0s - loss: 6971228.0000 - mae: 1872.9050 - val_loss: 12802168.0000 - val_mae: 2812.0068 - 37ms/epoch - 12ms/step\n",
      "Epoch 241/350\n",
      "3/3 - 0s - loss: 6285528.5000 - mae: 1862.6897 - val_loss: 12734464.0000 - val_mae: 2606.2424 - 37ms/epoch - 12ms/step\n",
      "Epoch 242/350\n",
      "3/3 - 0s - loss: 7081663.5000 - mae: 1909.1715 - val_loss: 14572144.0000 - val_mae: 2949.3469 - 38ms/epoch - 13ms/step\n",
      "Epoch 243/350\n",
      "3/3 - 0s - loss: 6771463.0000 - mae: 1908.2947 - val_loss: 13817405.0000 - val_mae: 2787.1121 - 36ms/epoch - 12ms/step\n",
      "Epoch 244/350\n",
      "3/3 - 0s - loss: 6508540.0000 - mae: 1807.4531 - val_loss: 13505405.0000 - val_mae: 2799.3066 - 37ms/epoch - 12ms/step\n",
      "Epoch 245/350\n",
      "3/3 - 0s - loss: 6390468.0000 - mae: 1903.9371 - val_loss: 13337007.0000 - val_mae: 2769.7517 - 37ms/epoch - 12ms/step\n",
      "Epoch 246/350\n",
      "3/3 - 0s - loss: 7083438.5000 - mae: 1917.4521 - val_loss: 13519307.0000 - val_mae: 2803.9729 - 38ms/epoch - 13ms/step\n",
      "Epoch 247/350\n",
      "3/3 - 0s - loss: 7582751.5000 - mae: 2098.7920 - val_loss: 12342489.0000 - val_mae: 2646.4758 - 37ms/epoch - 12ms/step\n",
      "Epoch 248/350\n",
      "3/3 - 0s - loss: 8649388.0000 - mae: 2209.8054 - val_loss: 12853145.0000 - val_mae: 2722.6460 - 39ms/epoch - 13ms/step\n",
      "Epoch 249/350\n",
      "3/3 - 0s - loss: 7923902.0000 - mae: 2202.7690 - val_loss: 14516745.0000 - val_mae: 2996.5371 - 38ms/epoch - 13ms/step\n",
      "Epoch 250/350\n",
      "3/3 - 0s - loss: 7275964.0000 - mae: 2097.9087 - val_loss: 13430903.0000 - val_mae: 2807.0125 - 37ms/epoch - 12ms/step\n",
      "Epoch 251/350\n",
      "3/3 - 0s - loss: 8210042.5000 - mae: 2214.3481 - val_loss: 14705152.0000 - val_mae: 3068.0437 - 38ms/epoch - 13ms/step\n",
      "Epoch 252/350\n",
      "3/3 - 0s - loss: 8544864.0000 - mae: 2229.4697 - val_loss: 14179037.0000 - val_mae: 2711.7405 - 38ms/epoch - 13ms/step\n",
      "Epoch 253/350\n",
      "3/3 - 0s - loss: 7519548.5000 - mae: 2074.0432 - val_loss: 19925206.0000 - val_mae: 3571.9065 - 39ms/epoch - 13ms/step\n",
      "Epoch 254/350\n",
      "3/3 - 0s - loss: 6289019.0000 - mae: 1943.7939 - val_loss: 17176312.0000 - val_mae: 3280.3779 - 39ms/epoch - 13ms/step\n",
      "Epoch 255/350\n",
      "3/3 - 0s - loss: 7926121.5000 - mae: 2147.1499 - val_loss: 15442989.0000 - val_mae: 3258.3665 - 43ms/epoch - 14ms/step\n",
      "Epoch 256/350\n",
      "3/3 - 0s - loss: 8059893.5000 - mae: 2181.1807 - val_loss: 12871009.0000 - val_mae: 2620.7119 - 40ms/epoch - 13ms/step\n",
      "Epoch 257/350\n",
      "3/3 - 0s - loss: 6389614.5000 - mae: 1818.7620 - val_loss: 13909501.0000 - val_mae: 2838.7341 - 40ms/epoch - 13ms/step\n",
      "Epoch 258/350\n",
      "3/3 - 0s - loss: 6226595.0000 - mae: 1757.6659 - val_loss: 13660744.0000 - val_mae: 2756.7073 - 37ms/epoch - 12ms/step\n",
      "Epoch 259/350\n",
      "3/3 - 0s - loss: 6124288.5000 - mae: 1760.5945 - val_loss: 13547201.0000 - val_mae: 2810.2988 - 37ms/epoch - 12ms/step\n",
      "Epoch 260/350\n",
      "3/3 - 0s - loss: 6080229.5000 - mae: 1763.0312 - val_loss: 13049445.0000 - val_mae: 2693.6521 - 39ms/epoch - 13ms/step\n",
      "Epoch 261/350\n",
      "3/3 - 0s - loss: 6113047.0000 - mae: 1738.5742 - val_loss: 14374080.0000 - val_mae: 2977.5637 - 38ms/epoch - 13ms/step\n",
      "Epoch 262/350\n",
      "3/3 - 0s - loss: 6915811.0000 - mae: 2031.6790 - val_loss: 13177299.0000 - val_mae: 2625.3372 - 37ms/epoch - 12ms/step\n",
      "Epoch 263/350\n",
      "3/3 - 0s - loss: 7072349.0000 - mae: 1933.0892 - val_loss: 13177473.0000 - val_mae: 2726.2952 - 39ms/epoch - 13ms/step\n",
      "Epoch 264/350\n",
      "3/3 - 0s - loss: 7221883.0000 - mae: 2109.0598 - val_loss: 14046828.0000 - val_mae: 2877.5735 - 37ms/epoch - 12ms/step\n",
      "Epoch 265/350\n",
      "3/3 - 0s - loss: 7218062.0000 - mae: 1973.6370 - val_loss: 13959715.0000 - val_mae: 2673.9482 - 38ms/epoch - 13ms/step\n",
      "Epoch 266/350\n",
      "3/3 - 0s - loss: 6017601.5000 - mae: 1827.5392 - val_loss: 16495047.0000 - val_mae: 3276.0176 - 37ms/epoch - 12ms/step\n",
      "Epoch 267/350\n",
      "3/3 - 0s - loss: 6615823.0000 - mae: 1973.0126 - val_loss: 13338120.0000 - val_mae: 2679.9812 - 38ms/epoch - 13ms/step\n",
      "Epoch 268/350\n",
      "3/3 - 0s - loss: 6425927.5000 - mae: 1840.7919 - val_loss: 14105941.0000 - val_mae: 2942.1736 - 39ms/epoch - 13ms/step\n",
      "Epoch 269/350\n",
      "3/3 - 0s - loss: 6922556.0000 - mae: 2029.8065 - val_loss: 12604189.0000 - val_mae: 2670.0378 - 38ms/epoch - 13ms/step\n",
      "Epoch 270/350\n",
      "3/3 - 0s - loss: 7026234.5000 - mae: 1918.2307 - val_loss: 13307163.0000 - val_mae: 2715.1406 - 38ms/epoch - 13ms/step\n",
      "Epoch 271/350\n",
      "3/3 - 0s - loss: 6276160.5000 - mae: 1845.5828 - val_loss: 14882883.0000 - val_mae: 3015.9395 - 38ms/epoch - 13ms/step\n",
      "Epoch 272/350\n",
      "3/3 - 0s - loss: 6882133.0000 - mae: 2049.7493 - val_loss: 13269797.0000 - val_mae: 2771.9368 - 37ms/epoch - 12ms/step\n",
      "Epoch 273/350\n",
      "3/3 - 0s - loss: 7563625.5000 - mae: 2038.0050 - val_loss: 12943977.0000 - val_mae: 2788.2344 - 38ms/epoch - 13ms/step\n",
      "Epoch 274/350\n",
      "3/3 - 0s - loss: 7102912.5000 - mae: 2091.1958 - val_loss: 14518228.0000 - val_mae: 2945.3574 - 37ms/epoch - 12ms/step\n",
      "Epoch 275/350\n",
      "3/3 - 0s - loss: 7311563.5000 - mae: 1967.3115 - val_loss: 13679163.0000 - val_mae: 2680.6716 - 38ms/epoch - 13ms/step\n",
      "Epoch 276/350\n",
      "3/3 - 0s - loss: 6872498.5000 - mae: 1870.7737 - val_loss: 14242916.0000 - val_mae: 2999.3928 - 39ms/epoch - 13ms/step\n",
      "Epoch 277/350\n",
      "3/3 - 0s - loss: 6211241.0000 - mae: 1841.4456 - val_loss: 13980712.0000 - val_mae: 2833.4773 - 39ms/epoch - 13ms/step\n",
      "Epoch 278/350\n",
      "3/3 - 0s - loss: 7226180.0000 - mae: 1960.0134 - val_loss: 15195081.0000 - val_mae: 3132.9883 - 42ms/epoch - 14ms/step\n",
      "Epoch 279/350\n",
      "3/3 - 0s - loss: 6843539.5000 - mae: 2056.6826 - val_loss: 13730416.0000 - val_mae: 2704.6614 - 40ms/epoch - 13ms/step\n",
      "Epoch 280/350\n",
      "3/3 - 0s - loss: 7795530.5000 - mae: 2067.3486 - val_loss: 14326313.0000 - val_mae: 2925.5769 - 38ms/epoch - 13ms/step\n",
      "Epoch 281/350\n",
      "3/3 - 0s - loss: 7419833.5000 - mae: 2205.9465 - val_loss: 13220184.0000 - val_mae: 2791.1165 - 39ms/epoch - 13ms/step\n",
      "Epoch 282/350\n",
      "3/3 - 0s - loss: 8501179.0000 - mae: 2127.2520 - val_loss: 12873611.0000 - val_mae: 2700.7976 - 40ms/epoch - 13ms/step\n",
      "Epoch 283/350\n",
      "3/3 - 0s - loss: 6836312.5000 - mae: 2015.9291 - val_loss: 15865969.0000 - val_mae: 3214.8293 - 38ms/epoch - 13ms/step\n",
      "Epoch 284/350\n",
      "3/3 - 0s - loss: 6803442.0000 - mae: 1953.2754 - val_loss: 15843128.0000 - val_mae: 3043.8210 - 38ms/epoch - 13ms/step\n",
      "Epoch 285/350\n",
      "3/3 - 0s - loss: 6726104.5000 - mae: 1884.4241 - val_loss: 18468654.0000 - val_mae: 3501.8201 - 38ms/epoch - 13ms/step\n",
      "Epoch 286/350\n",
      "3/3 - 0s - loss: 8429470.0000 - mae: 2334.6653 - val_loss: 13795796.0000 - val_mae: 2837.8464 - 38ms/epoch - 13ms/step\n",
      "Epoch 287/350\n",
      "3/3 - 0s - loss: 7990723.5000 - mae: 2157.4407 - val_loss: 13043020.0000 - val_mae: 2883.5186 - 37ms/epoch - 12ms/step\n",
      "Epoch 288/350\n",
      "3/3 - 0s - loss: 8322887.0000 - mae: 2323.8936 - val_loss: 12718364.0000 - val_mae: 2743.6575 - 37ms/epoch - 12ms/step\n",
      "Epoch 289/350\n",
      "3/3 - 0s - loss: 8440423.0000 - mae: 2152.3113 - val_loss: 13201005.0000 - val_mae: 2705.3396 - 38ms/epoch - 13ms/step\n",
      "Epoch 290/350\n",
      "3/3 - 0s - loss: 7933559.5000 - mae: 2254.9192 - val_loss: 14368781.0000 - val_mae: 2997.6836 - 37ms/epoch - 12ms/step\n",
      "Epoch 291/350\n",
      "3/3 - 0s - loss: 7021433.0000 - mae: 2029.5748 - val_loss: 13861664.0000 - val_mae: 2849.2019 - 37ms/epoch - 12ms/step\n",
      "Epoch 292/350\n",
      "3/3 - 0s - loss: 6727870.0000 - mae: 1922.4404 - val_loss: 17050218.0000 - val_mae: 3321.4631 - 38ms/epoch - 13ms/step\n",
      "Epoch 293/350\n",
      "3/3 - 0s - loss: 6965483.0000 - mae: 2041.7501 - val_loss: 14890283.0000 - val_mae: 2876.1604 - 37ms/epoch - 12ms/step\n",
      "Epoch 294/350\n",
      "3/3 - 0s - loss: 7464141.5000 - mae: 2004.5193 - val_loss: 14416813.0000 - val_mae: 2977.6016 - 38ms/epoch - 13ms/step\n",
      "Epoch 295/350\n",
      "3/3 - 0s - loss: 7483532.0000 - mae: 2162.2354 - val_loss: 12006816.0000 - val_mae: 2633.1824 - 37ms/epoch - 12ms/step\n",
      "Epoch 296/350\n",
      "3/3 - 0s - loss: 7124366.0000 - mae: 1931.4498 - val_loss: 12030436.0000 - val_mae: 2633.4231 - 38ms/epoch - 13ms/step\n",
      "Epoch 297/350\n",
      "3/3 - 0s - loss: 7044061.0000 - mae: 2026.8966 - val_loss: 13077221.0000 - val_mae: 2818.3621 - 39ms/epoch - 13ms/step\n",
      "Epoch 298/350\n",
      "3/3 - 0s - loss: 5960685.0000 - mae: 1781.6339 - val_loss: 14387941.0000 - val_mae: 2796.0037 - 37ms/epoch - 12ms/step\n",
      "Epoch 299/350\n",
      "3/3 - 0s - loss: 6583652.0000 - mae: 1831.5210 - val_loss: 15666744.0000 - val_mae: 3093.1868 - 37ms/epoch - 12ms/step\n",
      "Epoch 300/350\n",
      "3/3 - 0s - loss: 6543231.5000 - mae: 1985.8568 - val_loss: 13454221.0000 - val_mae: 2766.8513 - 37ms/epoch - 12ms/step\n",
      "Epoch 301/350\n",
      "3/3 - 0s - loss: 6439946.0000 - mae: 1789.3420 - val_loss: 12709437.0000 - val_mae: 2727.2263 - 38ms/epoch - 13ms/step\n",
      "Epoch 302/350\n",
      "3/3 - 0s - loss: 7131794.5000 - mae: 2059.6716 - val_loss: 11863887.0000 - val_mae: 2670.3167 - 36ms/epoch - 12ms/step\n",
      "Epoch 303/350\n",
      "3/3 - 0s - loss: 7608500.0000 - mae: 2048.0669 - val_loss: 12720731.0000 - val_mae: 2685.6184 - 37ms/epoch - 12ms/step\n",
      "Epoch 304/350\n",
      "3/3 - 0s - loss: 6275691.5000 - mae: 1901.7471 - val_loss: 16486628.0000 - val_mae: 3188.6492 - 37ms/epoch - 12ms/step\n",
      "Epoch 305/350\n",
      "3/3 - 0s - loss: 6708179.5000 - mae: 1879.7234 - val_loss: 13613216.0000 - val_mae: 2692.8411 - 37ms/epoch - 12ms/step\n",
      "Epoch 306/350\n",
      "3/3 - 0s - loss: 6304318.0000 - mae: 1791.2159 - val_loss: 13612331.0000 - val_mae: 2927.9641 - 39ms/epoch - 13ms/step\n",
      "Epoch 307/350\n",
      "3/3 - 0s - loss: 6557677.0000 - mae: 1907.0338 - val_loss: 11302701.0000 - val_mae: 2627.7893 - 37ms/epoch - 12ms/step\n",
      "Epoch 308/350\n",
      "3/3 - 0s - loss: 6223309.5000 - mae: 1806.9135 - val_loss: 12056192.0000 - val_mae: 2728.0625 - 38ms/epoch - 13ms/step\n",
      "Epoch 309/350\n",
      "3/3 - 0s - loss: 6774724.0000 - mae: 1940.8610 - val_loss: 12335835.0000 - val_mae: 2716.0349 - 39ms/epoch - 13ms/step\n",
      "Epoch 310/350\n",
      "3/3 - 0s - loss: 6996530.0000 - mae: 1988.3497 - val_loss: 13334164.0000 - val_mae: 2732.9890 - 37ms/epoch - 12ms/step\n",
      "Epoch 311/350\n",
      "3/3 - 0s - loss: 7348744.5000 - mae: 2087.9939 - val_loss: 17507268.0000 - val_mae: 3268.1013 - 37ms/epoch - 12ms/step\n",
      "Epoch 312/350\n",
      "3/3 - 0s - loss: 8016569.5000 - mae: 2187.0698 - val_loss: 16939158.0000 - val_mae: 3257.1926 - 37ms/epoch - 12ms/step\n",
      "Epoch 313/350\n",
      "3/3 - 0s - loss: 7983713.0000 - mae: 2178.7129 - val_loss: 17464570.0000 - val_mae: 3187.4368 - 37ms/epoch - 12ms/step\n",
      "Epoch 314/350\n",
      "3/3 - 0s - loss: 8079375.5000 - mae: 2180.5020 - val_loss: 17606922.0000 - val_mae: 3105.8567 - 36ms/epoch - 12ms/step\n",
      "Epoch 315/350\n",
      "3/3 - 0s - loss: 7783252.5000 - mae: 2128.5159 - val_loss: 18418814.0000 - val_mae: 3282.5742 - 37ms/epoch - 12ms/step\n",
      "Epoch 316/350\n",
      "3/3 - 0s - loss: 8526532.0000 - mae: 2228.1101 - val_loss: 17653970.0000 - val_mae: 3218.7969 - 40ms/epoch - 13ms/step\n",
      "Epoch 317/350\n",
      "3/3 - 0s - loss: 8206137.5000 - mae: 2237.5608 - val_loss: 15639889.0000 - val_mae: 3031.6941 - 40ms/epoch - 13ms/step\n",
      "Epoch 318/350\n",
      "3/3 - 0s - loss: 8830156.0000 - mae: 2243.7458 - val_loss: 15824819.0000 - val_mae: 3040.1384 - 41ms/epoch - 14ms/step\n",
      "Epoch 319/350\n",
      "3/3 - 0s - loss: 9232639.0000 - mae: 2389.0820 - val_loss: 15106113.0000 - val_mae: 3012.0125 - 39ms/epoch - 13ms/step\n",
      "Epoch 320/350\n",
      "3/3 - 0s - loss: 11077014.0000 - mae: 2659.9551 - val_loss: 15674165.0000 - val_mae: 2959.5186 - 37ms/epoch - 12ms/step\n",
      "Epoch 321/350\n",
      "3/3 - 0s - loss: 8255806.0000 - mae: 2363.1780 - val_loss: 17395692.0000 - val_mae: 3268.5928 - 37ms/epoch - 12ms/step\n",
      "Epoch 322/350\n",
      "3/3 - 0s - loss: 7888452.0000 - mae: 2302.0635 - val_loss: 16699507.0000 - val_mae: 3307.0117 - 37ms/epoch - 12ms/step\n",
      "Epoch 323/350\n",
      "3/3 - 0s - loss: 7578776.0000 - mae: 2133.7217 - val_loss: 19519510.0000 - val_mae: 3602.4016 - 37ms/epoch - 12ms/step\n",
      "Epoch 324/350\n",
      "3/3 - 0s - loss: 8553025.0000 - mae: 2305.6384 - val_loss: 14955376.0000 - val_mae: 3120.4470 - 36ms/epoch - 12ms/step\n",
      "Epoch 325/350\n",
      "3/3 - 0s - loss: 9117574.0000 - mae: 2301.0132 - val_loss: 14174848.0000 - val_mae: 2896.9836 - 36ms/epoch - 12ms/step\n",
      "Epoch 326/350\n",
      "3/3 - 0s - loss: 8647928.0000 - mae: 2352.5090 - val_loss: 13990839.0000 - val_mae: 2836.3606 - 37ms/epoch - 12ms/step\n",
      "Epoch 327/350\n",
      "3/3 - 0s - loss: 7596956.0000 - mae: 2062.4790 - val_loss: 14905836.0000 - val_mae: 3035.4365 - 37ms/epoch - 12ms/step\n",
      "Epoch 328/350\n",
      "3/3 - 0s - loss: 8997188.0000 - mae: 2428.1826 - val_loss: 15406080.0000 - val_mae: 3045.6824 - 37ms/epoch - 12ms/step\n",
      "Epoch 329/350\n",
      "3/3 - 0s - loss: 8008588.5000 - mae: 2192.1826 - val_loss: 13999096.0000 - val_mae: 3027.8523 - 38ms/epoch - 13ms/step\n",
      "Epoch 330/350\n",
      "3/3 - 0s - loss: 8434318.0000 - mae: 2288.6401 - val_loss: 14937037.0000 - val_mae: 3067.5469 - 37ms/epoch - 12ms/step\n",
      "Epoch 331/350\n",
      "3/3 - 0s - loss: 8562734.0000 - mae: 2292.5811 - val_loss: 15465251.0000 - val_mae: 2911.9558 - 37ms/epoch - 12ms/step\n",
      "Epoch 332/350\n",
      "3/3 - 0s - loss: 7158160.0000 - mae: 1998.0692 - val_loss: 15032501.0000 - val_mae: 3080.7617 - 37ms/epoch - 12ms/step\n",
      "Epoch 333/350\n",
      "3/3 - 0s - loss: 7802584.5000 - mae: 2066.2021 - val_loss: 12519185.0000 - val_mae: 2747.1230 - 37ms/epoch - 12ms/step\n",
      "Epoch 334/350\n",
      "3/3 - 0s - loss: 6644110.0000 - mae: 1897.8513 - val_loss: 12466967.0000 - val_mae: 2983.1453 - 36ms/epoch - 12ms/step\n",
      "Epoch 335/350\n",
      "3/3 - 0s - loss: 8395144.0000 - mae: 2294.5405 - val_loss: 10581716.0000 - val_mae: 2622.6672 - 37ms/epoch - 12ms/step\n",
      "Epoch 336/350\n",
      "3/3 - 0s - loss: 6846624.5000 - mae: 1907.7780 - val_loss: 11708547.0000 - val_mae: 2723.8508 - 36ms/epoch - 12ms/step\n",
      "Epoch 337/350\n",
      "3/3 - 0s - loss: 6723210.5000 - mae: 1988.3063 - val_loss: 11672152.0000 - val_mae: 2751.2849 - 36ms/epoch - 12ms/step\n",
      "Epoch 338/350\n",
      "3/3 - 0s - loss: 6453935.0000 - mae: 1841.9595 - val_loss: 10066279.0000 - val_mae: 2510.3992 - 37ms/epoch - 12ms/step\n",
      "Epoch 339/350\n",
      "3/3 - 0s - loss: 6149090.0000 - mae: 1840.5673 - val_loss: 10544397.0000 - val_mae: 2568.7852 - 37ms/epoch - 12ms/step\n",
      "Epoch 340/350\n",
      "3/3 - 0s - loss: 6232828.0000 - mae: 1871.4594 - val_loss: 10332572.0000 - val_mae: 2607.0774 - 36ms/epoch - 12ms/step\n",
      "Epoch 341/350\n",
      "3/3 - 0s - loss: 6292055.0000 - mae: 1838.8080 - val_loss: 10068060.0000 - val_mae: 2507.8071 - 38ms/epoch - 13ms/step\n",
      "Epoch 342/350\n",
      "3/3 - 0s - loss: 6797422.5000 - mae: 1923.9540 - val_loss: 11372101.0000 - val_mae: 2670.3267 - 42ms/epoch - 14ms/step\n",
      "Epoch 343/350\n",
      "3/3 - 0s - loss: 7273851.0000 - mae: 2051.2888 - val_loss: 12353299.0000 - val_mae: 2779.9407 - 41ms/epoch - 14ms/step\n",
      "Epoch 344/350\n",
      "3/3 - 0s - loss: 6879829.0000 - mae: 1936.2545 - val_loss: 11640931.0000 - val_mae: 2873.0830 - 41ms/epoch - 14ms/step\n",
      "Epoch 345/350\n",
      "3/3 - 0s - loss: 6567268.5000 - mae: 1927.9463 - val_loss: 11991799.0000 - val_mae: 2656.4465 - 44ms/epoch - 15ms/step\n",
      "Epoch 346/350\n",
      "3/3 - 0s - loss: 7651258.5000 - mae: 2126.5923 - val_loss: 10557308.0000 - val_mae: 2634.0649 - 43ms/epoch - 14ms/step\n",
      "Epoch 347/350\n",
      "3/3 - 0s - loss: 6937413.0000 - mae: 1954.4974 - val_loss: 12324991.0000 - val_mae: 2762.1873 - 54ms/epoch - 18ms/step\n",
      "Epoch 348/350\n",
      "3/3 - 0s - loss: 7467587.0000 - mae: 1986.0330 - val_loss: 12987245.0000 - val_mae: 2865.1316 - 43ms/epoch - 14ms/step\n",
      "Epoch 349/350\n",
      "3/3 - 0s - loss: 7055572.5000 - mae: 1904.1570 - val_loss: 10369232.0000 - val_mae: 2581.9834 - 41ms/epoch - 14ms/step\n",
      "Epoch 350/350\n",
      "3/3 - 0s - loss: 7092058.0000 - mae: 2002.8378 - val_loss: 10679853.0000 - val_mae: 2641.6255 - 40ms/epoch - 13ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.src.callbacks.History at 0x14def6260>"
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit(X_train, y_train, epochs=350, batch_size=32, verbose=2, validation_data=(X_test, y_test))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-25T10:47:15.582738Z",
     "start_time": "2023-07-25T10:46:58.194485Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 4: Evaluate the Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 10679853.000, RMSE: 3268.004, MAE: 2641.625\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "mse, mae = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('MSE: %.3f, RMSE: %.3f, MAE: %.3f' % (mse, np.sqrt(mse), mae))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-25T10:47:19.364141Z",
     "start_time": "2023-07-25T10:47:19.296712Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 5: Make Prediction"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 236ms/step\n",
      "Predicted: 15099.448\n"
     ]
    }
   ],
   "source": [
    "# Make a prediction\n",
    "row = np.asarray([18024.0, 16722.0, 14385.0, 21342.0, 17180.0]).reshape((1, n_steps))\n",
    "y_pred = model.predict(row)\n",
    "print('Predicted: %.3f' % (y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-25T10:47:23.838557Z",
     "start_time": "2023-07-25T10:47:23.541027Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[15787.441]], dtype=float32)"
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-25T10:45:05.597415Z",
     "start_time": "2023-07-25T10:45:05.589029Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
